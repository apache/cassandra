# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Contains definitions of all pipelines and jobs (test suites) in Apache Cassandra's CI.

# CI consists of:
#   1. job: a set of commands to run against a list of files containing tests
#   2. pipeline: a list of jobs that can be run in arbitrary order
#       pipelines contain a list of JDK's they have to be run across to certify correctness

#-----------------------------------------------------------------------------
# IMPLEMENTATION REQUIRED PARAMETERS:
#-----------------------------------------------------------------------------
# We do not provide a mechanism to transform the contents of $TEST_LIST_FILE into $TEST_SPLIT_FILE. Implementations
# must provide that mechanism and set that environment variable or "job->run:" operations will fail, unable to find a test split.
#
# EXPECTED FLOW ON AN AGENT:
# 1. Populate contents of $TEST_LIST_FILE for a given job using "job->test_list_cmd:" piped through "job->TEST_FILTER:"
# 2. Split up $TEST_LIST_FILE using "job->num_split_cmd:"
# 3. Populate $TEST_SPLIT_FILE with a given split (CI implementation specific)
# 3. Execute "job->run:" to run the given $TEST_SPLIT_FILE

#-----------------------------------------------------------------------------
# SOURCES
#-----------------------------------------------------------------------------
# You can configure the different sources you're using for your CI stack here; we default to HEAD on a given branch
# and you should print out what SHA you checked out and built against for reproducibility in a subsequent  investigation.
repos:
  cassandra:
    url: https://github.com/apache/cassandra
    branch: trunk
    sha: HEAD
  python_dtest:
    url: &python_dtest_url https://github.com/apache/cassandra-dtest
    branch: &python_dtest_branch trunk
    sha: HEAD
  cassandra-harry:
    url: https://github.com/apache/cassandra-harry
    branch: trunk
    sha: HEAD


#-----------------------------------------------------------------------------
# PIPELINES
#-----------------------------------------------------------------------------
pipelines:
  # All jobs in the pre-commit pipeline must run within constraints and pass
  # before a commit is merged upstream. Committers are expected to validate
  # and sign off on this if using non-reference CI environments.
  #
  # Failure to do so can lead to commits being reverted.
  - name: pre-commit
    jdk:
      - 11
    jobs:
      - unit
      - jvm-dtest
      - python-dtest
      - dtest
      - dtest-large
      - dtest-upgrade
      - dtest-upgrade-large
      - long-test
      - cqlsh-test

  # The post-commit pipeline is a larger set of tests that include all supported JDKs.
  # We expect different JDKs and variations on test suites to fail very rarely.
  #
  # Failures in these tests will be made visible on JIRA tickets shortly after
  # test run on reference CI and committers are expected to prioritize
  # rectifying any failures introduced by their work.
  - name: post-commit
    jdk:
      - 11
      - 17
    jobs:
      - unit
      - unit-cdc
      - compression
      - test-oa
      - test-system-keyspace-directory
      - test-tries
      - jvm-dtest
      - jvm-dtest-upgrade
      - dtest
      - dtest-novnode
      - dtest-offheap
      - dtest-large
      - dtest-large-novnode
      - dtest-upgrade
      - dtest-upgrade-large
      - long-test
      - cqlsh-test

  # These are longer-term, much more rarely changing pieces of infrastructure or
  # testing. We expect these to fail even more rarely than post-commit.
  - name: nightly
    jdk:
      - 11
      - 17
    jobs:
      - stress-test
      - fqltool-test
      - test-burn

#-----------------------------------------------------------------------------
# RESOURCE LIMITS, ALIASES, AND DEFAULT ENV VARS
#-----------------------------------------------------------------------------
# Downstream test orchestration needs to use <= the following values when running tests.
# Increasing these values indicates  a change in resource allocation https://ci-cassandra.apache.org/ and should not be done downstream.
small_executor: &small_executor {cpu: 4, memory: 1g, storage: 5g}
medium_executor: &medium_executor {cpu: 4, memory: 6g, storage: 25g}
large_executor: &large_executor {cpu: 4, memory: 16g, storage: 50g}

# On test addition or change, we repeat the job many times to try and suss out flakes. Instead of having it be bespoke
# per job, we want to provide some general guidelines for folks to default to and provide guidance on each test suite.
repeat_default: &repeat_many 500
repeat_less: &repeat_moderate 100
repeat_tiny: &repeat_few 25

# Default to at least one split
default_split_num: &default_split_num let NUM_SPLITS=$(( $(wc -l < "$TEST_LIST_FILE") / $SPLIT_SIZE )); if [ "$NUM_SPLITS" -eq 0 ]; then NUM_SPLITS=1; fi

# These env vars are required for tests to complete successfully given the run: commands, however downstream implementations
# are welcome to change them as needed to setup their env
default_env_vars: &default_env_vars
  ANT_HOME: /usr/share/ant
  KEEP_TEST_DIR: true
  CASSANDRA_DIR: /home/cassandra/cassandra
  CASSANDRA_DTEST_DIR: /home/cassandra/cassandra-dtest
  CCM_CONFIG_DIR: ${DIST_DIR}/.ccm
  TMPDIR: "$(mktemp -d)"
  DIST_DIR: "${CASSANDRA_DIR}/build"
  # Default to test.timeout as found in build.xml; should parse out of there in building local env and set this env var based on job
  TEST_TIMEOUT: 480000
  # Whether the repeated test iterations should stop on the first failure by default.
  REPEATED_TESTS_STOP_ON_FAILURE: false

# Anything specified in the required env vars SHOULD NOT BE CHANGED except for ASF CI; these are expected to have a
# material impact on test correctness and changes to them on a downstream system will likely destabilize our reference
# CI implementation
required_env_vars: &required_env_vars
  LANG: en_US.UTF-8
  PYTHONIOENCODING: "utf-8"
  PYTHONUNBUFFERED: true
  CASS_DRIVER_NO_EXTENSIONS: true
  CASS_DRIVER_NO_CYTHON: true
  #Skip all syncing to disk to avoid performance issues in flaky CI environments
  CASSANDRA_SKIP_SYNC: true
  CCM_MAX_HEAP_SIZE: "1024M"
  CCM_HEAP_NEWSIZE: "512M"
  PYTEST_OPTS: "-vv --log-cli-level=DEBUG --junit-xml=${DIST_DIR}/test/output/nosetests.xml --junit-prefix=${DTEST_TARGET} -s"

#-----------------------------------------------------------------------------
# JOBS
#
# By convention, anything in caps in the .yaml should be exported to an env var during the test run cycle.
#
# Parameters:
#   job: the name
#   resources: cpu: memory: storage: max allowable for the suite.
#   SPLIT_SIZE: This indicates how many tests to include in a given split. Can raise or lower as needed in your env.
#   REPEAT_COUNT: Number of times to repeat a test when multiplexing. *Do not lower below upstream config default.*
#   env:
#     TYPE: The type of test; this should translate into tests found under ${CASSANDRA_DIR}/test/${type} in $TEST_SPLIT_FILE
#     TEST_FILTER: filter to run after test_list_cmd to narrow down tests (splits, upgrade vs. non, etc)
#   test_list_cmd: command to run in shell to generate full list of tests to run. By default, randomizes test list by file name
#   num_split_cmd: Calculation that populates NUM_SPLITS based on suite, count, weighting.
#     *If you make changes to this value, they must be >= the default value*
#   run: command to run in shell to execute tests
#
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Single node JVM tests
#-----------------------------------------------------------------------------
jobs:
  - &job_unit
    name: unit
    resources: *medium_executor
    REPEAT_COUNT: *repeat_many
    SPLIT_SIZE: 20
    env:
      <<: *default_env_vars
      <<: *required_env_vars
      ANT_TEST_OPTS: -Dno-build-test=true
      # type lines up with the various targets in build.xml for usage by the <testclasslist> target
      TYPE: unit
      TEST_FILTER: ""
    TEST_LIST_FILE: ${DIST_DIR}/test_list.txt
    test_list_cmd: find "test/${type}" -name "*Test.java" ${TEST_FILTER:-} | sed "s;^test/${type}/;;" | sort -R > ${TEST_LIST_FILE}
    num_split_cmd: *default_split_num
    run: ant testclasslist -Dtest.classlistprefix=${type} -Dtest.timeout=${TEST_TIMEOUT} -Dtest.classlistfile=${TEST_SPLIT_FILE} ${ANT_TEST_OPTS}

  - <<: *job_unit
    name: test-cdc
    env_override:
      TYPE: test-cdc

  - <<: *job_unit
    name: test-compression
    env_override:
      TYPE: test-compression

  - <<: *job_unit
    name: test-oa
    env_override:
      TYPE: test-oa

  - <<: *job_unit
    name: test-system-keyspace-directory
    env_override:
      TYPE: test-system-keyspace-directory

  - <<: *job_unit
    name: test-trie
    env_override:
      TYPE: test-trie

  - <<: *job_unit
    name: microbench
    resources: *small_executor
    env_override:
      TYPE: microbench

  - <<: *job_unit
    name: fqltool-test
    resources: *small_executor
    env_override:
      TYPE: fqltool-test

  - <<: *job_unit
    name: stress-test
    resources: *small_executor
    env_override:
      TYPE: stress-test

  - <<: *job_unit
    name: long-test
    REPEAT_COUNT: *repeat_moderate
    env_override:
      TYPE: long-test

  - <<: *job_unit
    name: cqlsh-test
    run: ./pylib/cassandra-cqlsh-tests.sh $(pwd)
    resources: *small_executor
    env_override:
      TYPE: cqlsh-test

  - <<: *job_unit
    name: test-burn
    resources: *large_executor
    env_override:
      TYPE: test-burn


  #-----------------------------------------------------------------------------
  # JVM Multi-node tests
  #-----------------------------------------------------------------------------
  - <<: *job_unit
    name: jvm_dtest
    resources: *large_executor
    SPLIT_SIZE: 4
    REPEAT_COUNT: *repeat_moderate
    env_override:
      TYPE: distributed
      TEST_FILTER: "| grep -v -e upgrade/ -e fuzz/"

  - <<: *job_unit
    name: jvm-dtest-upgrade
    resources: *large_executor
    SPLIT_SIZE: 2
    REPEAT_COUNT: *repeat_few
    env_override:
      TYPE: distributed
      TEST_FILTER: "| grep upgrade/ -e fuzz/"


  #-----------------------------------------------------------------------------
  # Python Dtests
  #-----------------------------------------------------------------------------
  - &python_dtest
    name: python_dtest
    resources: *large_executor
    REPEAT_COUNT: *repeat_many
    SPLIT_SIZE: 4
    env:
      <<: *default_env_vars
      <<: *required_env_vars
      NUM_TOKENS: "16"
      DTEST_REPO: *python_dtest_url
      DTEST_BRANCH: *python_dtest_branch
      DTEST_TARGET: dtest
      # Should not be changed for a given job tag downstream
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --skip-resource-intensive-tests"
    TEST_LIST_FILE: ${DIST_DIR}/test_list.txt
    test_list_cmd: ./run_dtests.py --cassandra-dir=${CASSANDRA_DIR} ${DTEST_ARGS} --dtest-print-tests-only --dtest-print-tests-output=${TEST_LIST_FILE} 2>&1 > ${DIST_DIR}/test_stdout.txt
    num_split_cmd: *default_split_num
    run: pytest ${PYTEST_OPTS} --cassandra-dir=${CASSANDRA_DIR} --keep-failed-test-dir ${DTEST_ARGS} ${TEST_SPLIT_FILE} 2>&1 | tee -a ${DIST_DIR}/test_stdout.txt

  - <<: *python_dtest
    name: dtest-novnode
    env_override:
      DTEST_TARGET: "dtest-novnode"
      DTEST_ARGS: "--skip-resource-intensive-tests --keep-failed-test-dir"

  - <<: *python_dtest
    name: dtest-offheap
    env_overrides:
      DTEST_TARGET: "dtest-offheap"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --use-off-heap-memtables --skip-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-large
    REPEAT_COUNT: *repeat_moderate
    env_overrides:
      DTEST_TARGET: "dtest-large"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --only-resource-intensive-tests --force-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-large-nonode
    REPEAT_COUNT: *repeat_moderate
    env_overrides:
      DTEST_TARGET: "dtest-large-novnode"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --only-resource-intensive-tests --force-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-upgrade
    REPEAT_COUNT: *repeat_few
    SPLIT_SIZE: 2
    env_overrides:
      DTEST_TARGET: "dtest-upgrade"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --execute-upgrade-tests --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all"

  - <<: *python_dtest
    name: dtest-upgrade-large
    REPEAT_COUNT: *repeat_few
    SPLIT_SIZE: 2
    env_overrides:
      DTEST_TARGET: "dtest-upgrade-large"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --execute-upgrade-tests --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all --only-resource-intensive-tests --force-resource-intensive-tests"