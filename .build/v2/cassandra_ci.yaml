# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Contains definitions of all pipelines and jobs (test suites) in Apache Cassandra's CI.

# CI consists of:
#   1. job: a set of commands to run against a list of files containing tests
#   2. pipeline: a list of jobs that can be run in arbitrary order
#       pipelines contain a list of JDK's they have to be run across to certify correctness

#-----------------------------------------------------------------------------
# IMPLEMENTATION REQUIRED PARAMETERS:
#-----------------------------------------------------------------------------
# REQUIRED ENV VAR FOR NORMAL TESTS:
# TEST_SPLIT_FILE: the name of the files in which you'll be splitting out tests for parallelization
#
#
# REQUIRED ENV VAR FOR REPEATED TESTS:
# AGENT_COUNT: the count of agent executors you're running in your environment, used to constrain repeat runs to agent count
# BASE_DIR: Path to a base checkout of Cassandra
# BASE_BRANCH: The base branch to diff against to determine changed tests
#
#
# EXPECTED FLOW ON AN AGENT DURING NORMAL TESTING:
# 1. Populate contents of $TEST_LIST_FILE for a given job using "job->test_list_cmd:" piped through "job->TEST_FILTER:"
# 2. Populate $TEST_SPLIT_FILE with a given split (CI implementation specific)
# 3. Execute "job->run_cmd:" to run the given $TEST_SPLIT_FILE

#-----------------------------------------------------------------------------
# SOURCES
#-----------------------------------------------------------------------------
# You can configure the different sources you're using for your CI stack here; we default to HEAD on a given branch
# and you should print out what SHA you checked out and built against for reproducibility in a subsequent  investigation.
repos:
  cassandra:
    url: https://github.com/apache/cassandra
    branch: trunk
    sha: HEAD
  python_dtest:
    url: &python_dtest_url https://github.com/apache/cassandra-dtest
    branch: &python_dtest_branch trunk
    sha: HEAD
  cassandra-harry:
    url: https://github.com/apache/cassandra-harry
    branch: trunk
    sha: HEAD


#-----------------------------------------------------------------------------
# PIPELINES
#-----------------------------------------------------------------------------
pipelines:
  # All jobs in the pre-commit pipeline must run within constraints and pass
  # before a commit is merged upstream. Committers are expected to validate
  # and sign off on this if using non-reference CI environments.
  #
  # Failure to do so can lead to commits being reverted.
  - name: pre-commit
    jdk:
      - 11
    jobs:
      - unit
      - jvm-dtest
      - python-dtest
      - dtest-large
      - dtest-upgrade
      - dtest-upgrade-large
      - long-test
      - cqlsh-test

  # The post-commit pipeline is a larger set of tests that include all supported JDKs.
  # We expect different JDKs and variations on test suites to fail very rarely.
  #
  # Failures in these tests will be made visible on JIRA tickets shortly after
  # test run on reference CI and committers are expected to prioritize
  # rectifying any failures introduced by their work.
  - name: post-commit
    jdk:
      - 11
      - 17
    jobs:
      - unit
      - unit-cdc
      - compression
      - test-oa
      - test-system-keyspace-directory
      - test-tries
      - jvm-dtest
      - jvm-dtest-upgrade
      - dtest
      - dtest-novnode
      - dtest-offheap
      - dtest-large
      - dtest-large-novnode
      - dtest-upgrade
      - dtest-upgrade-large
      - long-test
      - cqlsh-test

  # These are longer-term, much more rarely changing pieces of infrastructure or
  # testing. We expect these to fail even more rarely than post-commit.
  - name: nightly
    jdk:
      - 11
      - 17
    jobs:
      - stress-test
      - fqltool-test
      - test-burn

#-----------------------------------------------------------------------------
# Resource limits, alises, supported versions, and required and optional env vars
#-----------------------------------------------------------------------------
# Downstream test orchestration needs to use <= the following values when running tests.
# Increasing these values indicates  a change in resource allocation https://ci-cassandra.apache.org/ and should not be done downstream.
small_executor: &small_executor { cpu: 4, memory: 1g, storage: 5g }
medium_executor: &medium_executor { cpu: 4, memory: 6g, storage: 25g }
large_executor: &large_executor { cpu: 4, memory: 16g, storage: 50g }

# On test addition or change, we repeat the job many times to try and suss out flakes. Instead of having it be bespoke
# per job, we want to provide some general guidelines for folks to default to and provide guidance on each test suite.
repeat_default: &repeat_many 500
repeat_less: &repeat_moderate 100
repeat_tiny: &repeat_few 25

# These values are required for tests to complete successfully given the run_cmd: commands, however downstream implementations
# are welcome to change them here or in the local env as needed to set up their env.
# Precedence is: env then override .yaml then values here
default_env_vars: &default_env_vars
  ANT_HOME: /usr/share/ant
  KEEP_TEST_DIR: true
  CASSANDRA_DIR: ~/cassandra
  DIST_DIR: "${CASSANDRA_DIR}/build"
  CCM_CONFIG_DIR: ${DIST_DIR}/.ccm
  CASSANDRA_DTEST_DIR: ~/cassandra-dtest
  DTEST_JAR_PATH: ~/dtest_jars
  CASSANDRA_CI_TMP_DIR: "$(mktemp -d)"
  # Default to test.timeout as found in build.xml; should parse out of there in building local env and set this env var based on job
  TEST_TIMEOUT: 480000
  # Whether the repeated test iterations should stop on the first failure by default.
  REPEATED_TESTS_STOP_ON_FAILURE: false
  NUM_TOKENS: "16"
  PYTHON_VERSION: "3.11"
  URL_TO_TEST: "REPLACE_ME"
  BRANCH_TO_TEST: "REPLACE_ME_BRANCH"

# Anything specified in the required env vars SHOULD NOT BE CHANGED except for ASF CI; these are expected to have a
# material impact on test correctness and changes to them on a downstream system will likely destabilize our reference
# CI implementation
required_env_vars: &required_env_vars
  LANG: en_US.UTF-8
  PYTHONIOENCODING: "utf-8"
  PYTHONUNBUFFERED: true
  CASS_DRIVER_NO_EXTENSIONS: true
  CASS_DRIVER_NO_CYTHON: true
  #Skip all syncing to disk to avoid performance issues in flaky CI environments
  CASSANDRA_SKIP_SYNC: true
  CCM_MAX_HEAP_SIZE: "1024M"
  # TODO: Reconcile Circle and ASF:
  #   - 512 on ASF, 256 on circle. Using circle's here; is this correct?
  CCM_HEAP_NEWSIZE: "256"
  PYTEST_OPTS: "-vv --log-cli-level=DEBUG --junit-xml=${DIST_DIR}/test/output/nosetests.xml --junit-prefix=${DTEST_TARGET} -s"
  SUPPORTED_CASSANDRA_VERSIONS: "cassandra-3.0" "cassandra-3.11" "cassandra-4.0" "cassandra-4.1" "cassandra-5.0"
  SUPPORTED_PYTHON_VERSIONS: "python3.6" "python3.8" "python3.11"

#-----------------------------------------------------------------------------
# JOBS
#
# By convention, anything in caps in the .yaml should be exported to an env var during the test run cycle.
#
# Parameters:
#   job: the name
#   resources: cpu: memory: storage: max allowable for the suite.
#   SPLIT_SIZE: This indicates how many tests to include in a given split. Can raise or lower as needed in your env.
#   env:
#     TYPE: The type of test; this should translate into tests found under ${CASSANDRA_DIR}/test/${type} in $TEST_SPLIT_FILE
#     TEST_FILTER: filter to run after test_list_cmd to narrow down tests (splits, upgrade vs. non, etc)
#   test_list_cmd: command to run in shell to generate full list of tests to run. By default, randomizes test list by file name
#   run_cmd: command to run in shell to execute tests
#
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Single node JVM tests
#-----------------------------------------------------------------------------
# TODO: Extract timeouts name from build.xml to here
jobs:
  - &jvm_base_job
    name: jvm_base_job
    resources: *medium_executor
    SPLIT_SIZE: 20
    env:
      <<: *default_env_vars
      <<: *required_env_vars
      ANT_TARGET: testclasslist
      ANT_TEST_OPTS: -Dno-build-test=true
      TEST_DIR: unit
      TEST_FILTER: ""
      # Corresponds to the tag value in build.xml containing the timeout for this test suite
      TEST_TIMEOUT: test.timeout
      # This is used as classlistprefix in the build.xml file
      REPEAT_COUNT: 500
      TEST_SPLITTER: split_jvm_tests
    # These reference methods found in ci_functions.sh and other .sh files in .build/*.sh. None take arguments and all
    # rely on the environment as setup in either the execution environment, env:, or env_overrides:
    before:
    - setup_environment
    - pretest_setup
    run:
    - run_jvm_tests
    after:
    - process_jvm_test_results

  # When we repeat tests, we want to repeat a specific list of tests
  - &repeat_jvm_diff
    env_overrides:
      TEST_SPLITTER: generate_diff_tests
    run: repeat_junit_tests

  # [unit] --------------------
  - <<: *jvm_base_job
    name: &unit unit

  - <<: *unit
    name: unit-repeat
    <<: *repeat_jvm_diff

  # [cdc] --------------------
  - <<: *jvm_base_job
    name: &cdc cdc
    env_overrides:
      ANT_TARGET: testclasslist-cdc

  - <<: *cdc
    name: cdc-repeat
    <<: *repeat_jvm_diff

  # [compression] --------------------
  - <<: *jvm_base_job
    name: &compression compression
    env_overrides:
      ANT_TARGET: testclasslist-compression

  - <<: *compression
    name: compression-repeat
    <<: *repeat_jvm_diff

  # [oa] --------------------
  - <<: *jvm_base_job
    name: &oa oa
    env_overrides:
      ANT_TARGET: testclasslist-oa

  - <<: *oa
    name: oa-repeat
    <<: *repeat_jvm_diff

  # [trie] --------------------
  - <<: *jvm_base_job
    name: &trie trie
    env_overrides:
      ANT_TARGET: testclasslist-trie

  - <<: *trie
    name: trie-repeat
    <<: *repeat_jvm_diff

  # [cqlsh] --------------------
  - <<: *jvm_base_job
    name: cqlsh
    env_overrides:
    run: run_cqlshlib_tests

  # [fqltool] --------------------
  - <<: *jvm_base_job
    name: fqltool
    resources: *small_executor
    env_overrides:
      ANT_TARGET: fqltool-test

  # [stress] --------------------
  - <<: *jvm_base_job
    name: stress
    resources: *small_executor
    env_overrides:
      ANT_TARGET: stress-test

  # [long] --------------------
  - <<: *jvm_base_job
    name: &long long
    env_overrides:
      REPEAT_COUNT: *repeat_moderate
      ANT_TARGET: long-test
      TEST_DIR: long
      TEST_TIMEOUT: test.long.timeout

  - <<: *long
    name: repeat-long
    <<: *repeat_jvm_diff

  # [burn] --------------------
  - <<: *jvm_base_job
    name: test-burn
    resources: *large_executor
    env_overrides:
      REPEAT_COUNT: *repeat_few
      TEST_DIR: burn
      ANT_TARGET: test-burn
      TEST_TIMEOUT: test.burn.timeout

  # [microbench] --------------------
  - <<: *jvm_base_job
    name: microbench
    env_overrides:
      CLASSLIST_PREFIX: microbench
      TEST_DIR: microbench


  #-----------------------------------------------------------------------------
  # JVM Multi-node tests
  #-----------------------------------------------------------------------------
  - <<: *jvm_base_job
    &jvm_dtest
    name: jvm-dtest
    resources: *large_executor
    SPLIT_SIZE: 4
    env_overrides:
      ANT_TARET: test-jvm-dtest-some
      TEST_DIR: distributed
      TEST_FILTER: "| grep -v -e upgrade/ -e fuzz/"
      TEST_TIMEOUT: test.distributed.timeout
      REPEAT_COUNT: *repeat_moderate
      TEST_SPLITTER: split_jvm_tests
    before:
      - setup_environment
      - pretest_setup
      - build_dtest_jars
    run:
    - run_jvm_tests
    after:
    - process_jvm_test_results

  - <<: *jvm_dtest
    name: jvm-dtest-repeat
    <<: *repeat_jvm_diff

  - <<: *jvm_dtest
    name: &jvm_dtest_upgrade jvm-dtest-upgrade
    SPLIT_SIZE: 2
    env_overrides:
      TEST_FILTER: "| grep upgrade/ -e fuzz/"
      REPEAT_COUNT: *repeat_few

  - <<: *jvm_dtest_upgrade
    name: jvm-dtest-upgrade-repeat
    <<: *repeat_jvm_diff


  #-----------------------------------------------------------------------------
  # Python Dtests
  #-----------------------------------------------------------------------------
  - &python_dtest
    name: python-dtest
    resources: *large_executor
    SPLIT_SIZE: 4
    env:
      <<: *default_env_vars
      <<: *required_env_vars
      DTEST_REPO: *python_dtest_url
      DTEST_BRANCH: *python_dtest_branch
      DTEST_TARGET: dtest
      # Should not be changed for a given job tag downstream
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --skip-resource-intensive-tests"
      TEST_SPLITTER: split_python_tests
    before:
    run:
    - run_python_tests
    after:
    - process_python_test_results

  - &repeat_python_diff
    env_overrides:
      TEST_SPLITTER: generate_diff_tests
    run: repeat_python_dtests

  - <<: *python_dtest
    name: python-dtest-repeat
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-novnode
    &novnode_params
    env_overrides:
      DTEST_TARGET: "dtest-novnode"
      DTEST_ARGS: "--skip-resource-intensive-tests --keep-failed-test-dir"

  - <<: *python_dtest
    name: dtest-novnode-repeat
    <<: *novnode_params
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-offheap
    &offheap_params
    env_overrides:
      DTEST_TARGET: "dtest-offheap"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --use-off-heap-memtables --skip-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-offheap-repeat
    <<: *offheap_params
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-large
    &large_params
    env_overrides:
      DTEST_TARGET: "dtest-large"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --only-resource-intensive-tests --force-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-large-repeat
    <<: *large_params
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-large-novnode
    &novnode_large_params
    env_overrides:
      DTEST_TARGET: "dtest-large-novnode"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --only-resource-intensive-tests --force-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-large-novnode-repeat
    <<: *novnode_large_params
    env_overrides:
      REPEAT_COUNT: *repeat_moderate
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-upgrade
    SPLIT_SIZE: 2
    &upgrade_params
    env_overrides:
      DTEST_TARGET: "dtest-upgrade"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --execute-upgrade-tests --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all"

  - <<: *python_dtest
    name: dtest-upgrade-repeat
    SPLIT_SIZE: 2
    <<: *upgrade_params
    env_overrides:
      REPEAT_COUNT: *repeat_few
    <<: *repeat_python_diff

  - <<: *python_dtest
    name: dtest-upgrade-large
    SPLIT_SIZE: 2
    &upgrade_large_params
    env_overrides:
      DTEST_TARGET: "dtest-upgrade-large"
      DTEST_ARGS: "--use-vnodes --num-tokens=${NUM_TOKENS} --execute-upgrade-tests --execute-upgrade-tests-only --upgrade-target-version-only --upgrade-version-selection all --only-resource-intensive-tests --force-resource-intensive-tests"

  - <<: *python_dtest
    name: dtest-upgrade-large-repeat
    SPLIT_SIZE: 2
    <<: *upgrade_large_params
    env_overrides:
      REPEAT_COUNT: *repeat_few
    <<: *repeat_python_diff