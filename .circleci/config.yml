---
# yamllint disable rule:line-length
version: 2.0

references:
  default_env_vars: &default_env_vars
    JAVA_HOME: /usr/local/openjdk8u154-cassandra-b02
    ANT_HOME: /usr/local/apache-ant-1.10.1
    LANG: en_US.UTF-8
    JDK_HOME: /usr/local/openjdk8u154-cassandra-b02
    JAVA8_HOME: /usr/local/openjdk8u154-cassandra-b02
    JAVA7_HOME: /usr/local/openjdk7u82-cassandra-b02
    KEEP_TEST_DIR: true
    DEFAULT_DIR: /home/cassandra/cassandra-dtest
    PYTHONIOENCODING: utf-8
    PYTHONUNBUFFERED: true
    CASS_DRIVER_NO_EXTENSIONS: true
    CASS_DRIVER_NO_CYTHON: true
    TEST_SUCCESS_OVERRIDE: /bin/false  # Used to make coverage tests pass

  # Settings for users who do not have a paid CircleCI account
  default_env_settings: &default_env_settings
    resource_class: medium
    parallelism: 4
  # Settings for users with high-capacity, paid CircleCI account
  high_capacity_env_settings: &high_capacity_env_settings
    resource_class: xlarge
    parallelism: 100

  # For environments with xlarge instances, use more memory
  high_capacity_env_vars: &high_capacity_env_vars
    <<: *default_env_vars
    CCM_MAX_HEAP_SIZE: 2048M
    CCM_HEAP_NEWSIZE: 512M
  # For environments with limited memory (e.g the free OSS CircleCI Tier)
  resource_constrained_env_vars: &resource_constrained_env_vars
    <<: *default_env_vars
    CCM_MAX_HEAP_SIZE: 1024M
    CCM_HEAP_NEWSIZE: 256M

  env_settings: &env_settings
    <<: *default_env_settings
    # <<: *high_capacity_env_settings

  env_vars: &env_vars
    <<: *resource_constrained_env_vars
    # <<: *high_capacity_env_vars

  container_config: &container_config
    docker:
      - image: kjellman/cassandra-test:0.4.3
        environment:
          <<: *env_vars
    working_directory: ~/

  workspace_root: &workspace_root
    /home/cassandra

  ### Reusable job steps
  attach_workspace: &attach_workspace
    attach_workspace:
      at: *workspace_root

  log_environment: &log_environment
    run:
      name: Log Environment Information
      command: |
        echo '*** id ***'
        id
        echo '*** cat /proc/cpuinfo ***'
        cat /proc/cpuinfo
        echo '*** free -m ***'
        free -m
        echo '*** df -m ***'
        df -m
        echo '*** ifconfig -a ***'
        ifconfig -a
        echo '*** uname -a ***'
        uname -a
        echo '*** mount ***'
        mount
        echo '*** env ***'
        env
        echo '*** cat $BASH_ENV ***'
        cat $BASH_ENV

  clone_cassandra: &clone_cassandra
    run:
      name: Clone Cassandra Repository (via git)
      command: |
        git clone --single-branch --depth 1 --branch $CIRCLE_BRANCH git://github.com/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME.git ~/cassandra
        cd ~/cassandra
        git remote show origin
        echo  "Cassandra Commit: $(git rev-parse HEAD) describe $(git describe --tags --long)"
        git shortlog --max-count 5

  clone_dtest: &clone_dtest
    run:
      name: Clone Cassandra dtest Repository (via git)
      command: |
        git clone --single-branch --branch master --depth 1 git://github.com/apache/cassandra-dtest.git ~/cassandra-dtest
        cd ~/cassandra-dtest
        git remote show origin
        echo  "DTest Commit: $(git rev-parse HEAD) describe $(git describe --tags --long)"
        git shortlog --max-count 5

  configure_java: &configure_java
    run:
      name: Configure Java environment
      command: |
        # BASH_ENV is sourced for each step (see https://circleci.com/docs/2.0/env-vars/),
        # and lives in /tmp so configure steps should be run once per job (which translates to per
        # container instance)
        echo 'export PATH=$PATH:$ANT_HOME/bin:$JAVA_HOME/bin' >> $BASH_ENV

  configure_dtest_python: &configure_dtest_python
    run:
      name: Configure virtualenv and python Dependencies
      command: |
        # note, this should be super quick as all dependencies should be pre-installed in the docker image
        # if additional dependencies were added to requirments.txt and the docker image hasn't been updated
        # we'd have to install it here at runtime -- which will make things slow, so do yourself a favor and
        # rebuild the docker image! (it automatically pulls the latest requirements.txt on build)
        source ~/env/bin/activate
        export CASS_DRIVER_NO_EXTENSIONS=true
        export CASS_DRIVER_NO_CYTHON=true
        pip3 install --exists-action w -r ~/cassandra-dtest/requirements.txt
        pip3 freeze
        # Persist activating virtualenv for other build steps - see configure_java for explanation
        echo 'source ~/env/bin/activate' >> $BASH_ENV

  determine_parallel_unit_tests_to_run: &determine_parallel_unit_tests_to_run
    run:
      name: Determine Tests to Run
      no_output_timeout: 15m
      command: |
        # reminder: this code (along with all the steps) is independently executed on every circle container
        # so the goal here is to get the circleci script to return the tests *this* container will run
        # which we do via the `circleci` cli tool.

        rm -fr ~/cassandra-dtest/upgrade_tests
        echo "***java tests***"

        # get all of our unit test filenames
        set -eo pipefail && circleci tests glob "$HOME/cassandra/test/unit/**/*.java" > /tmp/all_java_unit_tests.txt

        # split up the unit tests into groups based on the number of containers we have
        set -eo pipefail && circleci tests split --split-by=timings --timings-type=filename --index=${CIRCLE_NODE_INDEX} --total=${CIRCLE_NODE_TOTAL} /tmp/all_java_unit_tests.txt > /tmp/java_tests_${CIRCLE_NODE_INDEX}.txt
        set -eo pipefail && cat /tmp/java_tests_${CIRCLE_NODE_INDEX}.txt | cut -c 37-1000000 | grep "Test\.java$" > /tmp/java_tests_${CIRCLE_NODE_INDEX}_final.txt
        echo "** /tmp/java_tests_${CIRCLE_NODE_INDEX}_final.txt"
        cat /tmp/java_tests_${CIRCLE_NODE_INDEX}_final.txt

  run_parallel_unit_tests: &run_parallel_unit_tests
    run:
      name: Run Unit Tests
      no_output_timeout: 15m
      command: |
        #Skip all syncing to disk to avoid performance issues in flaky CI environments
        export CASSANDRA_SKIP_SYNC=true

        time cp -rp ~/cassandra /tmp
        cd /tmp/cassandra
        ant testclasslist -Dtest.classlistfile=/tmp/java_tests_${CIRCLE_NODE_INDEX}_final.txt || $TEST_SUCCESS_OVERRIDE

  # Determine which tests to run on this node
  # Requires environment variables set for the job
  #   DTEST_TESTS arguments for selecting dtests to run
  #   DTEST_SUFFIX suffix to add to dtest result files to disambiguate with_vnodes/no_vnodes
  determine_parallel_dtests_to_run: &determine_parallel_dtests_to_run
    run:
      name: Determine Tests to Run
      no_output_timeout: 5m
      command: |
        # reminder: this code (along with all the steps) is independently executed on every circle container
        # so the goal here is to get the circleci script to return the tests *this* container will run
        # which we do via the `circleci` cli tool.

        cd cassandra-dtest

        echo "***Collected DTests (with vnodes)***"
        set -eo pipefail && ./run_dtests.py ${DTEST_TESTS} --dtest-print-tests-only --skip-resource-intensive-tests --dtest-print-tests-output=/tmp/all_dtest_tests_${DTEST_SUFFIX}
        set -eo pipefail && circleci tests split --split-by=timings --timings-type=classname /tmp/all_dtest_tests_${DTEST_SUFFIX} > /tmp/split_dtest_tests_${DTEST_SUFFIX}.txt
        cat /tmp/split_dtest_tests_${DTEST_SUFFIX}.txt | tr '\n' ' ' > /tmp/split_dtest_tests_${DTEST_SUFFIX}_final.txt
        cat /tmp/split_dtest_tests_${DTEST_SUFFIX}_final.txt

  # Run parallel tests, requires same environment variables as determine_parallel_dtests_to_run
  run_parallel_dtests: &run_parallel_dtests
    run:
      name: Run dtests
      no_output_timeout: 15m
      command: |
        echo "cat /tmp/split_dtest_tests_${DTEST_SUFFIX}_final.txt"
        cat /tmp/split_dtest_tests_${DTEST_SUFFIX}_final.txt

        cd ~/cassandra-dtest
        mkdir -p /tmp/dtest

        echo "env: $(env)"
        echo "** done env"
        mkdir -p /tmp/results/dtests
        # we need the "set -o pipefail" here so that the exit code that circleci will actually use is from pytest and not the exit code from tee
        export SPLIT_TESTS=`cat /tmp/split_dtest_tests_${DTEST_SUFFIX}_final.txt`
        #Skip all syncing to disk to avoid performance issues in flaky CI environments
        export CASSANDRA_SKIP_SYNC=true
        set -o pipefail && cd ~/cassandra-dtest && (pytest --log-level="INFO" ${DTEST_TESTS} --junit-xml=/tmp/results/dtests/pytest_result_${DTEST_SUFFIX}.xml -s --cassandra-dir=/home/cassandra/cassandra --skip-resource-intensive-tests --keep-test-dir $SPLIT_TESTS 2>&1 || $TEST_SUCCESS_OVERRIDE) | tee /tmp/dtest/stdout.txt

default_jobs: &default_jobs
  jobs:
    - build
    - unit_tests:
        requires:
          - build
with_dtests_jobs: &with_dtest_jobs
  jobs:
    - build
    - unit_tests:
        requires:
          - build
    - dtests-with-vnodes:
        requires:
          - build
    - dtests-no-vnodes:
        requires:
          - build
with_dtest_jobs_only: &with_dtest_jobs_only
  jobs:
    - build
    - dtests-with-vnodes:
        requires:
          - build
    - dtests-no-vnodes:
        requires:
          - build

workflows:
  version: 2
  build_and_run_tests: *default_jobs
  # build_and_run_tests: *with_dtest_jobs_only
  # build_and_run_tests: *with_dtest_jobs
  # build_and_run_tests: *unittest-test-coverage
  # build_and_run_tests: *with_dtest_jobs_only-test-coverage
  # build_and_run_tests: *with_dtest_jobs-test-coverage

jobs:
  build:
    <<: *env_settings
    parallelism: 1  # This job doesn't benefit from parallelism
    <<: *container_config
    shell: /bin/bash -eo pipefail -l
    steps:
      - *clone_cassandra
      - *configure_java
      - *log_environment
      - run:
          name: Build Cassandra
          command: |
            cd ~/cassandra
            export JAVA_TOOL_OPTIONS=""-Dfile.encoding=UTF8""
            # Loop to prevent failure due to maven-ant-tasks not downloading a jar..
            for x in $(seq 1 3); do
                ${ANT_HOME}/bin/ant clean jar
                RETURN="$?"
                if [ "${RETURN}" -eq "0" ]; then
                    break
                fi
            done
            # Exit, if we didn't build successfully
            if [ "${RETURN}" -ne "0" ]; then
                echo "Build failed with exit code: ${RETURN}"
                exit ${RETURN}
            fi
          no_output_timeout: 15m
      - run:
          name: Run eclipse-warnings
          command: |
            cd ~/cassandra
            export JAVA_TOOL_OPTIONS=""-Dfile.encoding=UTF8""
            ant eclipse-warnings
      - persist_to_workspace:
          root: /home/cassandra
          paths:
            - cassandra
            - .m2
  unit_tests:
    <<: *env_settings
    <<: *container_config
    shell: /bin/bash -eo pipefail -l
    steps:
      - *attach_workspace
      - *configure_java
      - *log_environment
      - *determine_parallel_unit_tests_to_run
      - *run_parallel_unit_tests
      - store_test_results:
          path: /tmp/cassandra/build/test/output/
      - store_artifacts:
          path: /tmp/cassandra/build/test/output
          destination: junitxml
      - store_artifacts:
          path: /tmp/cassandra/build/test/logs
          destination: logs

  dtests-with-vnodes:
    <<: *env_settings
    <<: *container_config
    environment:
      DTEST_TESTS: --use-vnodes --num-tokens=32
      DTEST_SUFFIX: with_vnodes
    shell: /bin/bash -eo pipefail -l
    steps:
      - *attach_workspace
      - *clone_dtest
      - *configure_java
      - *configure_dtest_python
      - *log_environment
      - *determine_parallel_dtests_to_run
      - *run_parallel_dtests
      - store_test_results:
          path: /tmp/results
      - store_artifacts:
          path: /tmp/dtest
          destination: dtest_with_vnodes
      - store_artifacts:
          path: ~/cassandra-dtest/logs
          destination: dtest_with_vnodes_logs

  dtests-no-vnodes:
    <<: *env_settings
    <<: *container_config
    environment:
      DTEST_TESTS: ""  # default is test with no vnodes
      DTEST_SUFFIX: without_vnodes
    shell: /bin/bash -eo pipefail -l
    steps:
      - *attach_workspace
      - *clone_dtest
      - *configure_java
      - *configure_dtest_python
      - *log_environment
      - *determine_parallel_dtests_to_run
      - *run_parallel_dtests
      - store_test_results:
          path: /tmp/results
      - store_artifacts:
          path: /tmp/dtest
          destination: dtest_no_vnodes
      - store_artifacts:
          path: ~/cassandra-dtest/logs
          destination: dtest_no_vnodes_logs
